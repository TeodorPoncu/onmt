model_dir: dual_transformer/

data:
  source_tokenization: config/tokenization/aggressive.yml
  target_tokenization: config/tokenization/aggressive.yml
  source_vocabulary_1: data/dual_transformer/src-vocab.txt
  source_vocabulary_2: data/dual_transformer/skt-vocab.txt
  target_vocabulary: data/dual_transformer/tgt-vocab.txt
  train_features_file:
    - data/dual_transformer/src-train.txt
    - data/dual_transformer/skt-train.txt
  train_labels_file: data/dual_transformer/tgt-train.txt
  eval_features_file:
    - data/dual_transformer/src-val.txt
    - data/dual_transformer/skt-val.txt
  eval_labels_file: data/dual_transformer/tgt-val.txt

train:
  batch_type: tokens
  batch_size: 1024
  bucket_width: 1
  sample_buffer_size: 500000
  save_summary_steps: 100

params:
  optimizer: AdamOptimizer
  learning_rate: 1.0 # The scale constant.
  clip_gradients: null
  decay_step_duration: 8 # 1 decay step is 8 training steps.
  decay_type: noam_decay_v2
  decay_params:
    model_dim: 256
    warmup_steps: 2000 # (= 16000 training steps).
  start_decay_steps: 0

eval:
  # (optional) The batch size to use (default: 32).
  batch_size: 30

  # (optional) The number of threads to use for processing data in parallel (default: 1).
  num_threads: 1
  # (optional) The number of batches to prefetch asynchronously (default: 1).
  prefetch_buffer_size: 1

  # (optional) Evaluate every this many seconds (default: 18000).
  eval_delay: 7200

  # (optional) Save evaluation predictions in model_dir/eval/.
  save_eval_predictions: false
  # (optional) Evalutator or list of evaluators that are called on the saved evaluation predictions.
  # Available evaluators: sacreBLEU, BLEU, BLEU-detok, ROUGE
  external_evaluators: 
    - sacreBLEU
    - ROUGE 

  # (optional) Model exporter(s) to use during the training and evaluation loop:
  # last, final, best, or null (default: last).
  exporters: last

score:
  # (optional) The batch size to use (default: 64).
  batch_size: 64
  # (optional) The number of threads to use for processing data in parallel (default: 1).
  num_threads: 1
  # (optional) The number of batches to prefetch asynchronously (default: 1).
  prefetch_buffer_size: 1

  # (optional) Also report token-level cross entropy.
  with_token_level: true
  # (optional) Also output the alignments (can be: "null", "hard", default: "null").
  with_alignments: null