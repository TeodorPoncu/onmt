model_dir: sketch/

data:
  source_words_vocabulary: data/sketch/src-vocab.txt
  target_words_vocabulary: data/sketch/tgt-vocab.txt
  train_features_file: data/sketch/src-train.txt
  train_labels_file: data/sketch/tgt-train.txt
  eval_features_file: data/sketch/src-val.txt
  eval_labels_file: data/sketch/tgt-val.txt
train:
  batch_type: tokens
  batch_size: 1024
  bucket_width: 1
  sample_buffer_size: 500000
  save_summary_steps: 100
params:
  optimizer: AdamOptimizer
  learning_rate: 1.0 # The scale constant.
  clip_gradients: null
  decay_step_duration: 8 # 1 decay step is 8 training steps.
  decay_type: noam_decay_v2
  decay_params:
    model_dim: 256
    warmup_steps: 2000 # (= 16000 training steps).
  start_decay_steps: 0
beam_width: 5
length_penalty: 0.2
coverage_penalty: 0.2
replace_unknown_target: true
infer:
  batch_size: 1